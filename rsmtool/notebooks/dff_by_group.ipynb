{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(groups_desc) > 0:\n",
    "    markdown_str = [\"## Differential feature functioning\"]\n",
    "    markdown_str.append(\"This section shows differential feature functioning (DFF) plots \"\n",
    "                        \"for all features and subgroups. The features are shown after applying \"\n",
    "                        \"transformations (if applicable) and truncation of outliers.\")\n",
    "    display(Markdown('\\n'.join(markdown_str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-263ac3352e86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdf_train_preproc_merged\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mNameError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_train_preproc_merged' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-263ac3352e86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdf_train_preproc_merged\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mNameError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdf_train_preproc_merged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train_preproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train_metadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'spkitemid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroups_desc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# check if we already created the merged file in another notebook\n",
    "\n",
    "try:\n",
    "    df_train_preproc_merged\n",
    "except NameError:\n",
    "    df_train_preproc_merged = pd.merge(df_train_preproc, df_train_metadata, on = 'spkitemid')\n",
    "\n",
    "for group in groups_desc:\n",
    "    display(Markdown(\"### DFF by {}\".format(group)))\n",
    "    \n",
    "    if group in min_n_per_group:\n",
    "        display(Markdown(\"The report only shows the results for groups with \"\n",
    "                         \"at least {} responses in the training set.\".format(min_n_per_group[group])))\n",
    "        \n",
    "        category_counts = df_train_preproc_merged[group].value_counts()\n",
    "        selected_categories = category_counts[category_counts >= min_n_per_group[group]].index\n",
    "        \n",
    "        df_train_preproc_selected = df_train_preproc_merged[df_train_preproc_merged[group].isin(selected_categories)].copy()\n",
    "    else:\n",
    "        df_train_preproc_selected = df_train_preproc_merged.copy()\n",
    "    \n",
    "    \n",
    "    if len(df_train_preproc_selected) > 0:\n",
    "        \n",
    "        # we need to reduce col_wrap and increase width if the feature names are too long\n",
    "        if longest_feature_name > 10:\n",
    "            col_wrap = 2\n",
    "            # adjust height to allow for wrapping really long names. We allow 0.25 in per line\n",
    "            height = 2+(math.ceil(longest_feature_name/30)*0.25)\n",
    "            aspect = 5/height\n",
    "            # show legend near the second plot\n",
    "            plot_with_legend = 1\n",
    "        else:\n",
    "            height=3\n",
    "            col_wrap = 3\n",
    "            aspect = 1\n",
    "            plot_with_legend = 2\n",
    "        \n",
    "        selected_columns = ['spkitemid', 'sc1'] + features_used + [group]\n",
    "        df_melted = pd.melt(df_train_preproc_selected[selected_columns], id_vars=['spkitemid', 'sc1', group], var_name='feature')\n",
    "        group_values = sorted(df_melted[group].unique())\n",
    "        colors = sns.color_palette(\"Greys\", len(group_values))\n",
    "        with sns.axes_style('whitegrid'), sns.plotting_context('notebook', font_scale=1.2):\n",
    "            p = sns.catplot(x='sc1', y='value', hue=group, hue_order = group_values,\n",
    "                            col='feature', col_wrap=col_wrap, height=height, aspect=aspect,\n",
    "                            scale=0.6,\n",
    "                            palette=colors,\n",
    "                            sharey=False, sharex=False, legend=False, kind=\"point\",\n",
    "                            data=df_melted)\n",
    "\n",
    "            for i, axis in enumerate(p.axes):\n",
    "                axis.set_xlabel('score')\n",
    "                if i == plot_with_legend:\n",
    "                    legend = axis.legend(group_values, title=group, \n",
    "                                         frameon=True, fancybox=True, \n",
    "                                         ncol=1, fontsize=10,\n",
    "                                         loc='upper right', bbox_to_anchor=(1.75, 1))\n",
    "                    for j in range(len(group_values)):\n",
    "                        legend.legendHandles[j].set_color(colors[j])\n",
    "                    plt.setp(legend.get_title(), fontsize='x-small')\n",
    "            \n",
    "            for ax, cname in zip(p.axes, p.col_names):\n",
    "                ax.set_title('\\n'.join(wrap(str(cname), 30)))\n",
    "\n",
    "\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter('ignore')\n",
    "                plt.tight_layout(h_pad=1.0)\n",
    "\n",
    "            imgfile = join(figure_dir, '{}_dff_{}.svg'.format(experiment_id, group))\n",
    "            plt.savefig(imgfile)\n",
    "            if use_thumbnails:\n",
    "                show_thumbnail(imgfile, next(id_generator))\n",
    "            else:\n",
    "                plt.show()\n",
    "    else:\n",
    "        display(Markdown(\"None of the groups in {} had {} or more responses.\".format(group,\n",
    "                                                                                    min_n_per_group[group])))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
