{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0aa07b05-dcda-4828-8a1c-6af8b1536a2d",
   "metadata": {},
   "source": [
    "### SHAP plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0eb6dd-ca01-43fb-8289-8355ee1839ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "msg = (f\"These are general SHAP plots computed over the entire dataset. \"\n",
    "       f\"These plots display the **top {num_display_features} features** \"\n",
    "       \"according to the specific ranking metric for each plot. This number \"\n",
    "       \"can be adjusted by specifying a different integer value value for \"\n",
    "       \"the `num_features_to_display` option in the `rsmexplain` configuration file.\")\n",
    "\n",
    "display(Markdown(msg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad322e4",
   "metadata": {},
   "source": [
    "#### Heatmap Plot\n",
    "\n",
    "This plot offers a condensed, high-level overview of the entire dataset. It shows the instances on the x-axis, the model decisions on the y-axis, and the SHAP values encoded using a color scale. The instances are clustered by their explanation similarity. This means examples with similar model outputs for similar reasons are grouped together. \n",
    "\n",
    "The output of the model is shown above the heatmap matrix (centered around the explanationâ€™s base value), and the mean absolute impact of each model input shown as a bar plot on the right hand side of the plot. Features are ranked by mean absolute impact, i.e., the topmost feature in this plot has the highest average impact on model decisions for the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394b02dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shap.plots.heatmap(explanations, max_display=num_display_features, show=False)\n",
    "imgfile = join(fig_path, f\"{experiment_id}_heatmap.svg\")\n",
    "plt.savefig(imgfile, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d970f324",
   "metadata": {},
   "source": [
    "#### Heatmap plot ordered by prediction values\n",
    "\n",
    "This heatmap plot has its x-axis sorted in descending order of the model prediction, starting at the highest prediction down to the lowest prediction value\n",
    "\n",
    "This plot can be useful to spot features that display counter-intuitive behaviors or clustering. We expect the feature colors (which represent the shap value) to be on a gradient if they correlate with the model predictions. If the colors instead display clusters, then the feature does not necessarily correlate with the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a406866f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.heatmap(explanations,instance_order=explanations.sum(1), max_display=num_display_features, show=False)\n",
    "imgfile = join(fig_path, f\"{experiment_id}_heatmap_prediction_order.svg\")\n",
    "plt.savefig(imgfile, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d377663e",
   "metadata": {},
   "source": [
    "#### Global Bar Plot\n",
    "\n",
    "This plot gives a quick overview over the SHAP values of the data passed. Features are ranked by mean absolute impact. The number to the right of the bar represents the mean absolute shap value of that feature. The higher the mean shap value of your feature is, the higher the average contribution of that feature to a model decision is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20025cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(explanations, max_display=num_display_features, show=False)\n",
    "imgfile = join(fig_path, f\"{experiment_id}_global_bar.svg\")\n",
    "plt.savefig(imgfile, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd7cfab",
   "metadata": {},
   "source": [
    "#### Beeswarm Plot\n",
    "\n",
    "The beeswarm plot gives an information-dense overview over of the SHAP values. Each example in the data is represented by a dot on the given feature row in the plot.  The x-axis position of the dot is determined by the Shap value of that feature in that given decision. The further away from 0 a dot is, the higher the impact of that feature was for that decision. This impact can be negative (to the left) or positive (to the right).\n",
    "\n",
    "The feature value (*not* the Shap value!) is denoted by plot colors. Red signifies a high feature value and blue signifies a low feature value. Features are ranked by the mean-absolute impact they have on a model decision. The top feature in this plot will have the highest mean absolute impact. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6007d2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(explanations, max_display=num_display_features, show=False)\n",
    "imgfile = join(fig_path, f\"{experiment_id}_beeswarm.svg\")\n",
    "plt.savefig(imgfile, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdd912d",
   "metadata": {},
   "source": [
    "#### Beeswarm ranked by maximum impact\n",
    "\n",
    "This beeswarm plot is ranked by the absolute maximum impact of the features. The highest ranked feature in this plot will have the highest impact on the model decision. This can be useful to discover features that do not have a high average impact have a high maximum impact. This could represent features with outlier values, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38012a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(explanations, order=explanations.abs.max(0), max_display=num_display_features, show=False)\n",
    "imgfile = join(fig_path, f\"{experiment_id}_beeswarm_max_impact.svg\")\n",
    "plt.savefig(imgfile, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ebe795",
   "metadata": {},
   "source": [
    "#### Absolute mean beeswarm\n",
    "\n",
    "This plot is equivalent to the original beeswarm plot, but has the values transformed for absolute impact. This is useful to see how much impact a feature has on average while also displaying where those impact values are clustered. This can be considered a richer version of the global bar lot.\n",
    "\n",
    "**Important**: The beeswarm plot is known to have ordering issues due to a rounding effect. If the feature order does not match the order in the bar plot, then assume that the order in the bar plot is correct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079ff0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(explanations.abs, order=explanations.abs.mean(0), max_display=num_display_features, show=False)\n",
    "imgfile = join(fig_path, f\"{experiment_id}_beeswarm_abs_impact.svg\")\n",
    "plt.savefig(imgfile, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
