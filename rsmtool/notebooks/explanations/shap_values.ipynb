{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A brief introduction to shapley values\n",
    "\n",
    "SHAP values are generated through the [SHAP library](https://shap.readthedocs.io/en/latest/index.html) and are approximations of [Shapley Values](https://en.wikipedia.org/wiki/Shapley_value), a concept derived from game-theory. A very abbreviated explanation of how these values are generated: for every model decision passed to the explainer, the explainer considers how the model decision is impacted by removing that feature. For a more in-depth explanation consider this [summary article](https://towardsdatascience.com/understanding-how-ime-shapley-values-explains-predictions-d75c0fceca5a).\n",
    "\n",
    "Rsmexplain by default uses the [Sampling](https://shap.readthedocs.io/en/latest/generated/shap.explainers.Sampling.html#shap.explainers.Sampling) explainer model, which computes shap values through a method described [here](https://link.springer.com/article/10.1007/s10115-013-0679-x).\n",
    "\n",
    "The sampling explainer is model agnostic, meaning it should in principle work for any type of model. Rsmexplain currently only supports regressors. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to read shap values\n",
    "\n",
    "Shap values are additive representations of a feature's impact on a model decision. The sum of all shap values and the base value for a prediction should yield the actual model output.\n",
    "\n",
    "A shap value for a feature can be considered that feature's contribution to the decision during that specific prediction. By calculating an absolute mean of all shap values of a feature, we can calculate an average impact for the data that was passed to the explainer. Absolute mean shap values are saved in \"/csv_files/mean_shap_values.csv\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to consider\n",
    "\n",
    "Rsmexplain can only generate shap values for the data passed in the \"explainable_data\" and \"range\" parameters. If the dataset passed is small, then the values derived cannot be considered representative of the model as a whole. Plots that display mean values for your shap values should be taken with a grain of salt if your passed data was small, or not representative of the typical data the model deals with.\n",
    "\n",
    "As long as sufficiently large background set was passed, the individual values for predictions can be considered trustworthy.\n",
    "\n",
    "If you wish to investigate your shap values by hand, please refer to files in \"/csv_files/\".\n",
    "\n",
    "If you wish to use the generated shap Explanation object, you may unpickle \"explanation.pkl\". Your initial row ids are stored in \"ids.pkl\" in a dictionary format of \\{array index: actual index\\}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An overview over your shap values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a quick text overview over your shap values. Please refer to the Plots section for visualizations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Absolute Mean Shap Values\n",
    "\n",
    "The top 5 features in terms of absolute mean impact were:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(mean_values[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following features have an absolute mean shap value of 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    value0 = mean_values.loc[mean_values['abs. mean shap value'].isin([0])]\n",
    "    display(value0)\n",
    "except:\n",
    "    display(Markdown(\"No features with a mean value of 0 found.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If features appear in the above list with a mean shap value of 0, then those features did not contribute to the model decisions. If the data set passed was large and representative of the data the model usually encounters, then this may mean that those features are not useful for the model.\n",
    "\n",
    "Before you draw conclusions, make sure that those features were not simply set to 0 in all data instances that were passed to the model. This might accidentally create this effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Absolute Max Shap Values\n",
    "\n",
    "Here are the top 5 features in terms of absolute maximal impact:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(max_values[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the features in the above list do not overlap with the top 5 in terms of absolute mean impact, then these features have high outlier values, but less overall average impact."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
