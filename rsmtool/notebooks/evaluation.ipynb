{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall association statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_str = (\"The tables in this section show the standard association metrics between \"\n",
    "                \"*observed* human scores and different types of machine scores. \"\n",
    "                \"These results are computed on the evaluation set. `raw_trim` scores \"\n",
    "                \"are truncated to [{}, {}]. `raw_trim_round` scores are computed by first truncating \"\n",
    "                \"and then rounding the predicted score. Scaled scores are computed by re-scaling \"\n",
    "                \"the predicted scores using mean and standard deviation of human scores as observed \"\n",
    "                \"on the training data and mean and standard deviation of machine scores as predicted \"\n",
    "                \"for the training set.\".format(min_score, max_score))\n",
    "display(Markdown(markdown_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descriptive holistic score statistics\n",
    "\n",
    "The table shows distributional properties of human and system scores. SMD values lower then -0.15 or higher than 0.15 are <span class=\"highlight_color\">highlighted</span>.\n",
    "\n",
    "*Please note that for raw scores, SMD values are likely to be affected by possible differences in scale.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_or_scaled = \"scaled\" if use_scaled_predictions else \"raw\"\n",
    "eval_file = join(output_dir, '{}_eval.{}'.format(experiment_id, file_format))\n",
    "df_eval = DataReader.read_from_file(eval_file, index_col=0)\n",
    "distribution_columns = ['N', 'h_mean', 'sys_mean', 'h_sd',  'sys_sd', 'h_min', 'sys_min', 'h_max', 'sys_max', 'SMD']\n",
    "association_columns = ['N'] + [column for column in df_eval.columns if not column in distribution_columns]\n",
    "df_distribution = df_eval[distribution_columns]\n",
    "df_association = df_eval[association_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.width=10\n",
    "formatter = partial(color_highlighter, low=-0.15, high=0.15)\n",
    "HTML('<span style=\"font-size:95%\">'+ df_distribution.to_html(classes=['sortable'], \n",
    "                                                             escape=False,\n",
    "                                                             formatters={'SMD': formatter},\n",
    "                                                             float_format=float_format_func) + '</span>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Association statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_str = ['The table shows the standard association metrics between human scores and machine scores.']\n",
    "if continuous_human_score:\n",
    "    markdown_str.append(\"Note that for computation of `kappa` both human and machine scores are rounded.\")\n",
    "else:\n",
    "    markdown_str.append(\"Note that for computation of `kappa` all machine scores are rounded.\")\n",
    "\n",
    "Markdown('\\n'.join(markdown_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.width=10\n",
    "HTML('<span style=\"font-size:95%\">'+ df_association.to_html(classes=['sortable'], \n",
    "                                                            escape=False,\n",
    "                                                            float_format=float_format_func) + '</span>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_str = [\"Confusion matrix using {}, trimmed, and rounded scores and human scores (rows=human, columns=system).\".format(raw_or_scaled)]\n",
    "\n",
    "if continuous_human_score:\n",
    "    markdown_str.append(\"Note: Human scores have beeen rounded to the nearest integer.\")\n",
    "            \n",
    "Markdown('\\n'.join(markdown_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "confmat_file = join(output_dir, '{}_confMatrix.{}'.format(experiment_id, file_format))\n",
    "df_confmat = DataReader.read_from_file(confmat_file, index_col=0)\n",
    "df_confmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of human and machine scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "markdown_strs = [\"The histogram and the table below show the distibution of \"\n",
    "                 \"human scores and {}, trimmed, and rounded machine scores \"\n",
    "                 \"(as % of all responses).\".format(raw_or_scaled)]\n",
    "markdown_strs.append(\"Differences in the table between human and machine distributions \"\n",
    "                     \"larger than 5 percentage points are <span class='highlight_color'>highlighted</span>.\")\n",
    "if continuous_human_score:\n",
    "    markdown_strs.append(\"Note: Human scores have beeen rounded to the nearest integer.\")\n",
    "    \n",
    "display(Markdown('\\n'.join(markdown_strs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scoredist_file = join(output_dir, '{}_score_dist.{}'.format(experiment_id, file_format))\n",
    "df_scoredist = DataReader.read_from_file(scoredist_file, index_col=0)\n",
    "df_scoredist_melted = pd.melt(df_scoredist, id_vars=['score'])\n",
    "df_scoredist_melted = df_scoredist_melted[df_scoredist_melted['variable'] != 'difference']\n",
    "\n",
    "# get the colors for the plot\n",
    "colors = sns.color_palette(\"Greys\", 2)\n",
    "\n",
    "with sns.axes_style('whitegrid'):\n",
    "\n",
    "    # make a barplot without a legend since we will \n",
    "    # add one manually later\n",
    "    p = sns.catplot(x=\"score\", y=\"value\", hue=\"variable\", kind=\"bar\",\n",
    "                    palette=colors, data=df_scoredist_melted, \n",
    "                    height=3, aspect=2, legend=False)\n",
    "    p.set_axis_labels('score', '% of responses')\n",
    "    \n",
    "    # add a legend with the right colors\n",
    "    axis = p.axes[0][0]\n",
    "    legend = axis.legend(labels=('Human', 'Machine'), title='', frameon=True, fancybox=True)\n",
    "    legend.legend_handles[0].set_color(colors[0])\n",
    "    legend.legend_handles[1].set_color(colors[1])\n",
    "\n",
    "    imgfile = join(figure_dir, '{}_score_dist.svg'.format(experiment_id))\n",
    "    plt.savefig(imgfile)\n",
    "\n",
    "    if use_thumbnails:\n",
    "        show_thumbnail(imgfile, next(id_generator))\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "formatter = partial(color_highlighter, low=0, high=5, absolute=True)\n",
    "df_html = df_scoredist.to_html(classes=['sortable'], index=False, \n",
    "                               escape=False, formatters={'difference': formatter})\n",
    "display(HTML(df_html))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
