{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Responses excluded due to non-numeric feature values or scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_missing_rows_train = len(df_train_orig) - len(df_train)\n",
    "pct_missing_rows_train = round(num_missing_rows_train/len(df_train_orig))\n",
    "num_missing_rows_test = len(df_test_orig) - len(df_test)\n",
    "pct_missing_rows_test = round(num_missing_rows_test/len(df_test_orig)*100, 1)\n",
    "\n",
    "html_strings = []\n",
    "html_strings.append('<i>Training set: </i>{} ({}% of the original {})'.format(num_missing_rows_train, pct_missing_rows_train, len(df_train_orig)))\n",
    "html_strings.append('<br/>')\n",
    "html_strings.append('<i>Evaluation set: </i>{} ({}% of the original {})'.format(num_missing_rows_test, pct_missing_rows_test, len(df_test_orig)))\n",
    "html_strings.append('<br/><br/>')\n",
    "html_strings.append('The rest of this report is based only on the responses used to build and train the model.')\n",
    "HTML(''.join(html_strings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make the table showing candidate (speaker), prompt \n",
    "# and responses stats for training and test\n",
    "\n",
    "train_responses = set(df_train['spkitemid'])\n",
    "train_ids_prompts_lists = df_train['spkitemid'].apply(lambda x: x.split('-'))\n",
    "train_candidates = set(map(operator.itemgetter(0), train_ids_prompts_lists))\n",
    "train_prompts = set(map(operator.itemgetter(1), train_ids_prompts_lists))\n",
    "\n",
    "test_responses = set(df_test['spkitemid'])\n",
    "test_ids_prompts_lists = df_test['spkitemid'].apply(lambda x: x.split('-'))\n",
    "test_candidates = set(map(operator.itemgetter(0), test_ids_prompts_lists))\n",
    "test_prompts = set(map(operator.itemgetter(1), test_ids_prompts_lists))\n",
    "\n",
    "rows = [{'partition': 'Training', 'responses': len(train_responses), \n",
    "         'prompts': len(train_prompts), 'candidates': len(train_candidates)},\n",
    "        {'partition': 'Evaluation', 'responses': len(test_responses), \n",
    "         'prompts': len(train_prompts), 'candidates': len(train_candidates)},\n",
    "        {'partition': 'Overlapping', 'responses': len(train_responses & test_responses), \n",
    "         'prompts': len(train_prompts & test_prompts), 'candidates': len(train_candidates & test_candidates)},\n",
    "        {'partition': 'Total', 'responses': len(train_responses | test_responses), \n",
    "         'prompts': len(train_prompts | test_prompts), 'candidates': len(train_candidates | test_candidates)}]\n",
    "\n",
    "df = pd.DataFrame.from_dict(rows)\n",
    "df = df[['partition', 'responses', 'prompts', 'candidates']]\n",
    "HTML(df.to_html(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "html_strings = []\n",
    "avg_resp_prompt_train, avg_resp_prompt_test = len(train_responses) / len(train_prompts), len(test_responses) / len(test_prompts)\n",
    "avg_resp_cands_train, avg_resp_cands_test = len(train_responses) / len(train_candidates), len(test_responses) / len(test_candidates)\n",
    "html_strings.append('Average responses per candidate: {} for training, {} for evaluation'.format(avg_resp_cands_train, avg_resp_cands_test))\n",
    "html_strings.append('<br/>')\n",
    "html_strings.append('Average responses per prompt: {} for training, {} for evaluation'.format(avg_resp_prompt_train, avg_resp_prompt_test))\n",
    "HTML(''.join(html_strings))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
