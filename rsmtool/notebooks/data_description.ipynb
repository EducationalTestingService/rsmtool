{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    num_excluded_train = len(df_train_responses_with_excluded_flags)\n",
    "except NameError:\n",
    "    num_excluded_train = 0\n",
    "\n",
    "try:\n",
    "    num_excluded_test = len(df_test_responses_with_excluded_flags)\n",
    "except NameError:\n",
    "    num_excluded_test = 0\n",
    "\n",
    "if context == 'rsmtool':\n",
    "    pct_excluded_train = round(100*num_excluded_train/len(df_train_orig), 2)\n",
    "pct_excluded_test = round(100*num_excluded_test/len(df_test_orig), 2)\n",
    "\n",
    "if (num_excluded_train != 0 or num_excluded_test != 0):\n",
    "    display(Markdown(\"### Responses excluded due to flags\"))\n",
    "\n",
    "    display(Markdown(\"Total number of responses excluded due to flags:\"))\n",
    "    if context=='rsmtool':\n",
    "        display(Markdown(\"Training set: {} responses ({:.1f}% of the original {} responses)\".format(num_excluded_train, pct_excluded_train, len(df_train_orig))))\n",
    "    display(Markdown(\"Evaluation set: {} responses ({:.1f}% of the original {} responses)\".format(num_excluded_test, pct_excluded_test, len(df_test_orig))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Responses excluded due to non-numeric feature values or scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    num_missing_rows_train = len(df_train_excluded)\n",
    "except NameError:\n",
    "    num_missing_rows_train = 0\n",
    "\n",
    "if context == 'rsmtool':\n",
    "    pct_missing_rows_train = 100*num_missing_rows_train/len(df_train_orig)\n",
    "\n",
    "try:\n",
    "    num_missing_rows_test = len(df_test_excluded)\n",
    "except:\n",
    "    num_missing_rows_test = 0\n",
    "pct_missing_rows_test = 100*num_missing_rows_test/len(df_test_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "excluded_candidates_note = Markdown(\"Note: if a candidate had less than {} responses left for analysis after applying all filters, \"\n",
    "                                    \"all responses from that \"\n",
    "                                    \"candidate were excluded from further analysis.\".format(min_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if context == 'rsmtool':\n",
    "    display(Markdown(\"**Training set**\"))\n",
    "    display(Markdown('Total number of excluded responses: {} ({:.1f}% of the original {})'.format(num_missing_rows_train, pct_missing_rows_train, len(df_train_orig))))\n",
    "    if num_missing_rows_train != 0:\n",
    "        train_excluded_analysis_file = join(output_dir, '{}_train_excluded_composition.{}'.format(experiment_id,\n",
    "                                                                                                  file_format))\n",
    "        df_train_excluded_analysis = DataReader.read_from_file(train_excluded_analysis_file)\n",
    "        display(HTML(df_train_excluded_analysis.to_html(classes=['sortable'], float_format=float_format_func, index=False))) \n",
    "        if min_items > 0:\n",
    "            display(excluded_candidates_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "display(Markdown('**Evaluation set**'))\n",
    "display(Markdown('Total number of excluded responses: {} ({:.1f}% of the original {})'.format(num_missing_rows_test, pct_missing_rows_test, len(df_test_orig))))\n",
    "if num_missing_rows_test != 0:\n",
    "    test_excluded_analysis_file = join(output_dir, '{}_test_excluded_composition.{}'.format(experiment_id,\n",
    "                                                                                            file_format))\n",
    "    df_test_excluded_analysis = DataReader.read_from_file(test_excluded_analysis_file)\n",
    "    display(HTML(df_test_excluded_analysis.to_html(classes=['sortable'], float_format=float_format_func, index=False)))\n",
    "    if min_items > 0:\n",
    "        display(excluded_candidates_note)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of this report is based only on the responses that were not excluded above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if context == 'rsmtool':\n",
    "    display(Markdown('### Composition of the training and evaluation sets'))\n",
    "elif context == 'rsmeval':\n",
    "    display(Markdown('### Composition of the evaluation set'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show the table showing candidate (speaker), prompt \n",
    "# and responses stats for training and test\n",
    "\n",
    "# feature descriptives extra table\n",
    "data_composition_file = join(output_dir, '{}_data_composition.{}'.format(experiment_id, file_format))\n",
    "df_data_desc = DataReader.read_from_file(data_composition_file)\n",
    "display(HTML(df_data_desc.to_html(classes=['sortable'], float_format=float_format_func, index=False)))\n",
    "\n",
    "try:\n",
    "    num_double_scored_responses = len(df_test_human_scores[df_test_human_scores['sc2'].notnull()])\n",
    "except NameError:\n",
    "    pass\n",
    "else:\n",
    "    zeros_included_or_excluded = 'excluded' if exclude_zero_scores else 'included'\n",
    "    display(Markdown(\"Total number of double scored responses in the evaluation set\" \n",
    "                     \" used: {} (zeros {})\".format(num_double_scored_responses,\n",
    "                                                   zeros_included_or_excluded)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
