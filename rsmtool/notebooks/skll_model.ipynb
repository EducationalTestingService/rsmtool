{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "objective_used = skll_objective if skll_objective else 'neg_mean_squared_error'\n",
    "intro_markdown_str = f\"\"\"### Characteristics \n",
    "\n",
    "- Model: **{model_name}**\n",
    "- Number of features: **{len(features_used)}**\n",
    "- Tuning objective: **{objective_used}**\n",
    "\"\"\"\n",
    "\n",
    "if skll_fixed_parameters:\n",
    "    intro_markdown_str += \"- Custom fixed parameters:\"\n",
    "    for parameter, value in skll_fixed_parameters.items():\n",
    "        intro_markdown_str += f\"\\n    - `{parameter}` : **{value!r}**\"\n",
    "\n",
    "display(Markdown(intro_markdown_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skll_linear_models = ['Ridge', 'BayesianRidge', 'LinearSVR', 'Lasso', 'Lars', 'HuberRegressor', 'TheilSenRegressor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_markdown_str = \"\"\"### Feature weights\n",
    "\n",
    "Here are the feature weights as learned by the model.\"\"\"\n",
    "\n",
    "if model_name in skll_linear_models:\n",
    "    display(Markdown(weights_markdown_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if model_name in skll_linear_models:\n",
    "\n",
    "    from rsmtool.modeler import Modeler\n",
    "    from six import iteritems\n",
    "    from sklearn.svm import SVR\n",
    "    \n",
    "    model_file = join(output_dir, '{}.model'.format(experiment_id))\n",
    "    learner = Modeler.load_from_file(model_file).learner\n",
    "    \n",
    "    # get the coefficients and the intercept\n",
    "    weights = {}\n",
    "    coef = learner.model.coef_\n",
    "    intercept = {'_intercept_': learner.model.intercept_}\n",
    "\n",
    "    # convert SVR coefficient format (1 x matrix) to array\n",
    "    if isinstance(learner._model, SVR):\n",
    "        coef = coef.toarray()[0]\n",
    "\n",
    "    # inverse transform to get indices for before feature selection\n",
    "    coef = learner.feat_selector.inverse_transform(coef.reshape(1, -1))[0]\n",
    "    for feat, idx in iteritems(learner.feat_vectorizer.vocabulary_):\n",
    "        if coef[idx]:\n",
    "            weights[feat] = coef[idx]\n",
    "\n",
    "    # Some learners (e.g. LinearSVR) may return a list of intercepts\n",
    "    if isinstance(intercept['_intercept_'], np.ndarray):\n",
    "        intercept_list = [\"%.12f\" % i for i in intercept['_intercept_']]\n",
    "        print(\"intercept = {}\".format(intercept_list))\n",
    "    else:\n",
    "        print(\"intercept = {:.12f}\".format(intercept['_intercept_']))\n",
    "    print()\n",
    "        \n",
    "    print(\"Number of nonzero features:\", len(weights))\n",
    "    weight_items = iteritems(weights)\n",
    "    for feat, val in sorted(weight_items, key=lambda x: -abs(x[1])):\n",
    "        print(\"{:.12f}\\t{}\".format(val, feat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
