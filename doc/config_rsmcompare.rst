.. _config_file_rsmcompare:

Experiment configuration file
"""""""""""""""""""""""""""""

This is a file in ``.json`` format that provides overall configuration options for an ``rsmcompare`` experiment. Here's an example configuration file for `rsmcompare <https://github.com/EducationalTestingService/rsmtool/blob/master/examples/rsmcompare/config_rsmcompare.json>`_.

There are seven required fields and the rest are all optional.

comparison_id
~~~~~~~~~~~~~
An identifier for the comparison experiment that will be used to name the report. It can be any combination of alphanumeric values, must *not* contain spaces, and must *not* be any longer than 200 characters.

experiment_id_old
~~~~~~~~~~~~~~~~~
An identifier for the "baseline" experiment. This ID should be identical to the ``experiment_id`` used when the baseline experiment was run, whether ``rsmtool`` or ``rsmeval``. The results for this experiment will be listed first in the comparison report.

experiment_id_new
~~~~~~~~~~~~~~~~~
An identifier for the experiment with the "new" model (e.g., the model with new feature(s)). This ID should be identical to the ``experiment_id`` used when the experiment was run, whether ``rsmtool`` or ``rsmeval``. The results for this experiment will be listed first in the comparison report.

experiment_dir_old
~~~~~~~~~~~~~~~~~~
The directory with the results for the "baseline" experiment. This directory is the output directory that was used for the experiment and should contain subdirectories ``output`` and ``figure`` generated by ``rsmtool`` or ``rsmeval``.

experiment_dir_new
~~~~~~~~~~~~~~~~~~
The directory with the results for the experiment with the new model. This directory is the output directory that was used for the experiment and should contain subdirectories ``output`` and ``figure`` generated by ``rsmtool`` or ``rsmeval``.

description_old
~~~~~~~~~~~~~~~
A brief description of the "baseline" experiment. The description can contain spaces and punctuation.

description_new
~~~~~~~~~~~~~~~
A brief description of the experiment with the new model. The description can contain spaces and punctuation.

use_scaled_predictions_old *(Optional)*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Set to ``true`` if the "baseline" experiment used scaled machine scores for confusion matrices, score distributions, subgroup analyses, etc. Defaults to ``false``.

use_scaled_predictions_new *(Optional)*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Set to ``true`` if the experiment with the new model used scaled machine scores for confusion matrices, score distributions, subgroup analyses, etc. Defaults to ``false``.

.. warning::

    For ``rsmtool`` and ``rsmeval``, primary evaluation analyses are computed on both raw and scaled scores, but some analyses (e.g., the confusion matrix) are only computed for either raw or re-scaled scores based on the value of ``use_scaled_predictions``. ``rsmcompare`` uses the existing outputs and does not perform any additional evaluations. Therefore if this field was set to ``true`` in the original experiment but is set to ``false`` for ``rsmcompare``, the report will be internally inconsistent: some evaluations use raw scores whereas others will use scaled scores.

subgroups *(Optional)*
~~~~~~~~~~~~~~~~~~~~~~
A list of column names indicating grouping variables used for generating analyses specific to each of those defined subgroups.For example, ``["prompt, gender, native_language, test_country"]``.

.. note::

    In order to include subgroups analyses in the comparison report, both experiments must have been run with the same set of subgroups.

.. _general_sections_rsmcompare:

general_sections *(Optional)*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
RSMTool provides pre-defined sections for ``rsmcompare`` (listed below) and, by default, all of them are included in the report. However, you can choose a subset of these pre-defined sections by specifying a list as the value for this field.

    - ``feature_descriptives``: Compares the descriptive statistics for all raw feature values included in the model:

        - a table showing mean, standard deviation, skewness and kurtosis;
        - a table showing the number of truncated outliers for each feature; and
        - a table with percentiles and outliers;
        - a table with correlations between raw feature values and human score in each model and the correlation between the values of the same feature in these two models. Note that this table only includes features and responses which occur in both training sets.


    - ``features_by_group``: Shows boxplots for both experiments with distributions of raw feature values by each of the :ref:`subgroups <subgroups_rsmtool>` specified in the configuration file.

    - ``preprocessed_features``: Compares analyses of preprocessed features:

        - histograms showing the distributions of preprocessed features values;
        - the correlation matrix between all features and the human score;
        - a table showing marginal correlations between all features and the human score; and
        - a table showing partial correlations between all features and the human score.

    - ``preprocessed_features_by_group``: Compares analyses of preprocessed features by subgroups: marginal and partial correlations between each feature and human score for each subgroup.

    - ``consistency``: Compares metrics for human-human agreement and the difference ('degradation') between the human-human and human-system agreement.

    - ``score_distributions``:

        - tables showing the distributions for both human and machine scores; and

        - confusion matrices for human and machine scores.

    - ``model``: Compares the parameters of the two regression models. For linear models, it also includes the standardized and relative coefficients.

    - ``evaluation``: Compares the standard set of evaluations recommended for scoring models on the evaluation data.

    - ``pca``: Shows the results of principal components analysis on the processed feature values for the new model only:

        - the principal components themselves;
        - the variances; and
        - a Scree plot.

    - ``notes``: Notes explaining the terminology used in comparison reports.

    - ``sysinfo``: Shows all Python packages along with versions installed in the current environment while generating the report.



.. _custom_sections_rsmcompare:

custom_sections *(Optional)*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~
A list of custom, user-defined sections to be included into the final report. These are IPython notebooks (``.ipynb`` files) created by the user.  The list must contains paths to the notebook files, either absolute or relative to the configuration file. All custom notebooks have access to some :ref:`pre-defined variables <custom_notebooks>`.

.. _special_sections_rsmcompare:

special_sections *(Optional)*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
A list specifying special ETS-only comparison sections to be included into the final report. These sections are available *only* to ETS employees via the `rsmextra` package.

section_order *(Optional)*
~~~~~~~~~~~~~~~~~~~~~~~~~~
A list containing the order in which the sections in the report should be generated. Any specified order must explicitly list:

    1. Either *all* pre-defined sections if a value for the :ref:`general_sections <general_sections_rsmcompare>` field is not specified OR the sections specified using :ref:`general_sections <general_sections_rsmcompare>`, and

    2. *All* custom section names specified using :ref:`custom_ sections <custom_sections_rsmcompare>`, i.e., file prefixes only, without the path and without the `.ipynb` extension, and

    3. *All* special sections specified using :ref:`special_sections <special_sections_rsmcompare>`.
