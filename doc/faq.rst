.. _faq:

.. |br| raw:: html

   <div style="line-height: 0; padding: 0; margin: 0"></div>

.. |hr| raw:: html

   <hr/>

Frequently Asked Questions
==========================

.. _q_train_deep_learning:

:fa:`quora`. **Can I train a deep learning model using RSMTool?** [:ref:`#
<q_train_deep_learning>`]

``rsmtool`` supports a large number of :ref:`learners <rsmtool_model>` but not deep
learning algorithms. However, you can still use :ref:`rsmeval <usage_rsmeval>`
to obtain a comprehensive evaluation report from any model.

|hr|

.. _q_change_report:

:fa:`quora`. **How can I customize** ``rsmtool`` **and** ``rsmeval``
**reports?** [:ref:`# <q_change_report>`]

The reports generated by ``rsmtool``  and ``rsmeval`` are designed to be fully
customizable. You can:

- Omit sections using the :ref:`general_sections <general_sections_rsmtool>`
  configuration option;

- Change the order of the sections using the :ref:`section_order
  <rsmtool_section_order>` option;

- Create your own :ref:`"custom" sections <custom_notebooks>`.

|hr|

.. _q_no_response_remaining:

:fa:`quora`. **I get the following error:** ``No responses remaining after filtering out
non-numeric feature values. No further analysis can be run.`` **What
happened?** [:ref:`# <q_no_response_remaining>`]

``rsmtool`` is designed to work only with numeric features. Non-numeric values
*including* missing values are filtered out. Some of the common reasons for this
error are:

- The human score column or one of the features contains only non-numeric
  values. You can either exclude this feature or convert it to one-hot
  encoding.

- You have features with missing values. The solution is to replace
  missing values with zeros. Note that this applies *even* if you use the
  ``.jsonlines`` format.  We have an open `issue
  <https://github.com/EducationalTestingService/rsmtool/issues/480>`_ to
  provide an option to automatically convert missing values to zeros.

- You have a lot of missing feature values and none of the responses has
  numeric features for every single feature. Inspect the
  :ref:`*_excluded_responses<rsmtool_excluded_responses>` files in the output
  directory to see what responses have been excluded.

|hr|

.. _q_multiple_models:

:fa:`quora`. **Can I pass a set of learners to the** ``model`` **option in the
configuration file or do I need a separate run for each leaner I want to try?**
[:ref:`# <q_multiple_models>`]

``rsmtool`` cannot train multiple models via a configuration file. If you wish
to use multiple learners/models, you should use the :ref:`RSMTool API <api>`
instead of the command line.

|hr|

.. _q_how_to_predict_with_model:

:fa:`quora`. **Can I compute predictions on new data using a model trained
with** ``rsmtool`` **?** [:ref:`# <q_how_to_predict_with_model>`]

Yes! We have built :ref:`rsmpredict<usage_rsmpredict>` to do exactly this!

|hr|

.. _q_changed_feature_signs:

:fa:`quora`. **Why did** ``rsmtool`` **change the sign of some features in**
``feature.csv`` **? I thought** ``rsmtool`` **assumes a positive sign for all
features?** [:ref:`# <q_changed_feature_signs>`]

``rsmtool`` indeed assumes a default positive sign for all raw features.
However, if you set ``select_transformations`` to ``true`` in your experiment
configuration file,  RSMTool will automatically apply
:ref:`transformations<select_transformations_rsmtool>` to some of the features.
Some transformations such as ``inv`` (inverse transform) change the polarity of
the feature.  In such cases, RSMTool takes this into account and changes the
sign accordingly. See :ref:`note here<clever_sign_note>`.

|hr|

.. _q_mismatched_rsmpredict_rsmtool:

:fa:`quora`. I ran ``rsmpredict`` to generate predicted scores using a model
trained with ``rsmtool``. I used the evaluation set from ``rsmtool`` as the input
data for ``rsmpredict``. I expected the number of excluded/included responses
to be the same. However, for some reason, ``rsmpredict`` generated the
predicted scores for more cases than ``rsmtool``.
[:ref:`# <q_mismatched_rsmpredict_rsmtool>`]

The situation described here often occurs in the following situation.

1. ``rsmtool`` is run with one of the built-in :ref:`feature selection
   models<automatic_feature_selection_models>` and excludes responses where
   *any* of the candidate features has missing/non-numeric values in either
   the training or the evaluation set. Next, it performs the feature selection,
   trains a model with those features using the filtered training set and
   generates predictions on the filtered test set.

2. ``rsmpredict`` is now run to generate predictions on the evaluation set
   using the trained model and excludes *only* those responses where any of the
   *selected* features (a subset of the original features) has
   missing/non-numeric values.

As a result, there is a mismatch in the number of predictions generated by
``rsmtool`` and ``rsmpredict``.

|hr|

.. _q_relative_betas_not_one:

:fa:`quora`. **The relative betas for the linear regression model in my**
``rsmtool`` **run do not sum to 1. Is that a problem?** [:ref:`#
<q_relative_betas_not_one>`]

Please check if your model has any negative coefficients. Relative coefficients
*only* make sense when all model coefficients are positive. Their sum is
expected to be less than 1 if there are negative coefficients. Note that if
this is the case the relative coefficients will *not* be included into the report.

.. _q_wandb:

:fa:`quora`. **Can I use Weights & Biases to log artifacts and reports?**
[:ref:`# <q_wandb>`]

Yes! W&B logging is natively supported the following command-line tools:
``rsmtool``, ``rsmeval``, ``rsmxval``, ``rsmexplain``, ``rsmcompare``, and
``rsmsummarize``. To enable it, set the :ref:`use_wandb <use_wandb>`
configuration option to ``true`` and set the :ref:`wandb_entity <wandb_entity>`
and :ref:`wandb_project <wandb_project>` options appropriately.

|hr|

.. _q_autogenerate_config:

:fa:`quora`. **It's so difficult to remember all the configuration options.**
[:ref:`# <q_autogenerate_config>`]

We agree that it can be quite overwhelming to remember all the configuration
options. This is why all command-line tools support :ref:`automatic generation
of configuration files <autogen_configuration>`!
